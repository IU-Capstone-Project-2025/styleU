{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb1eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), # try smaller things as details not that important\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "label_map = {\n",
    "    'autumn': 0,\n",
    "    'spring': 1,\n",
    "    'summer': 2,\n",
    "    'winter': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a7f8f",
   "metadata": {},
   "source": [
    "In color_type_clip:\n",
    "\n",
    "- `clustered_by_color_type_manually_cleaned` was used for training\n",
    "- `reference` was used for validation \n",
    "- `test` for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b65296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_tensors(path, transform):\n",
    "    X = []  \n",
    "    y = []  \n",
    "\n",
    "    for label_name, label_id in label_map.items():\n",
    "        folder = os.path.join(path, label_name)\n",
    "        print(folder)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                new_path = os.path.join(folder, filename)\n",
    "                try:\n",
    "                    image = Image.open(new_path).convert(\"RGB\")\n",
    "                    image_tensor = transform(image)\n",
    "                    X.append(image_tensor)\n",
    "                    y.append(label_id)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with file {new_path}: {e}\")\n",
    "\n",
    "    X = torch.stack(X)\n",
    "    y = torch.tensor(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4efe25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustered_by_color_type_manually_cleaned/autumn\n",
      "clustered_by_color_type_manually_cleaned/spring\n",
      "clustered_by_color_type_manually_cleaned/summer\n",
      "clustered_by_color_type_manually_cleaned/winter\n",
      "reference/autumn\n",
      "reference/spring\n",
      "reference/summer\n",
      "reference/winter\n"
     ]
    }
   ],
   "source": [
    "# Train and validation datasers load \n",
    " \n",
    "X_train, y_train = images_to_tensors('clustered_by_color_type_manually_cleaned/', train_transform)\n",
    "X_val, y_val = images_to_tensors('reference/', val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e2df701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset load\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for filename in os.listdir('tests'):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        path = os.path.join('tests', filename)\n",
    "        try:\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "            image_tensor = val_transform(image)\n",
    "            X.append(image_tensor)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with file {path}: {e}\")\n",
    "\n",
    "X_test = torch.stack(X)\n",
    "df = pd.read_csv('true_labels.csv')\n",
    "y_test = df['color_type'].map(label_map).values\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fac6e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7addad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b25b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 16 * 16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09906929",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8147f0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 189.8514, Accuracy: 40.91%\n",
      "Epoch 0: Val Loss=0.9240, Val Acc=47.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 169.4059, Accuracy: 48.14%\n",
      "Epoch 1: Val Loss=0.9596, Val Acc=50.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 156.9191, Accuracy: 53.71%\n",
      "Epoch 2: Val Loss=1.0350, Val Acc=47.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 145.9823, Accuracy: 57.14%\n",
      "Epoch 3: Val Loss=1.0577, Val Acc=45.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 126.7272, Accuracy: 62.37%\n",
      "Epoch 4: Val Loss=1.1920, Val Acc=40.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 105.7027, Accuracy: 67.84%\n",
      "Epoch 5: Val Loss=1.1689, Val Acc=52.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 87.5846, Accuracy: 74.12%\n",
      "Epoch 6: Val Loss=1.2352, Val Acc=47.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 67.3951, Accuracy: 78.81%\n",
      "Epoch 7: Val Loss=2.0453, Val Acc=42.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 56.4693, Accuracy: 83.02%\n",
      "Epoch 8: Val Loss=1.6838, Val Acc=50.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 43.5147, Accuracy: 86.03%\n",
      "Epoch 9: Val Loss=2.9028, Val Acc=42.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weights = torch.tensor([1.0, 2.7, 3.1, 1.0], device=device)  # обратные пропорции\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total = 0 \n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = correct / total * 100\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    val_acc = correct / total * 100\n",
    "    print(f\"Epoch {epoch}: Val Loss={val_loss/len(val_loader):.4f}, Val Acc={val_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e91ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)  # суммируем loss по батчу\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b714843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.4035, Test Accuracy: 0.2644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.403454265375247, 0.26436781609195403)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False), criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "137b1c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnn_model.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'cnn_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
