{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-13T13:27:31.017001Z",
     "start_time": "2025-06-13T13:26:06.621024Z"
    }
   },
   "source": [
    "\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "# 1. Setting up the environment \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# 2. Uploading references from folders (each folder is a color type)\n",
    "reference_folder = \"clustered_by_color_type\"\n",
    "reference_embeddings = []\n",
    "reference_labels = []\n",
    "\n",
    "for label in os.listdir(reference_folder):\n",
    "    label_path = os.path.join(reference_folder, label)\n",
    "    if not os.path.isdir(label_path):\n",
    "        continue\n",
    "    for file in os.listdir(label_path):\n",
    "        if file.endswith((\".jpg\", \".jpeg\")):\n",
    "            image_path = os.path.join(label_path, file)\n",
    "            if not os.path.isfile(image_path): \n",
    "                print(f\"Skipped missing file: {image_path}\")\n",
    "                continue\n",
    "            try:\n",
    "                image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    emb = model.encode_image(image)\n",
    "                reference_embeddings.append(emb / emb.norm(dim=-1, keepdim=True))\n",
    "                reference_labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "\n",
    "# 3. Downloading all images from the tests folder\n",
    "test_folder = \"tests\"\n",
    "test_images = [f for f in os.listdir(test_folder) if f.endswith((\".jpg\", \".jpeg\"))]\n",
    "\n",
    "# 4. Type prediction for each image\n",
    "print(\"\\n Predicted types for images in 'tests':\\n\")\n",
    "\n",
    "for test_img_name in test_images:\n",
    "    test_image_path = os.path.join(test_folder, test_img_name)\n",
    "    test_image = preprocess(Image.open(test_image_path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        test_embedding = model.encode_image(test_image)\n",
    "    test_embedding = test_embedding / test_embedding.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    similarities = [cosine_similarity(test_embedding, ref_emb).item() for ref_emb in reference_embeddings]\n",
    "    best_index = int(np.argmax(similarities))\n",
    "    predicted_type = reference_labels[best_index]\n",
    "\n",
    "    print(f\" {test_img_name}: {predicted_type.capitalize()}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predicted types for images in 'tests':\n",
      "\n",
      " test1.jpg: Spring\n",
      " test10.jpg: Winter\n",
      " test11.jpg: Spring\n",
      " test12.jpeg: Winter\n",
      " test13.jpeg: Winter\n",
      " test14.jpeg: Autumn\n",
      " test15.jpeg: Autumn\n",
      " test16.jpeg: Spring\n",
      " test17.jpeg: Autumn\n",
      " test18.jpeg: Autumn\n",
      " test19.jpeg: Winter\n",
      " test2.jpg: Spring\n",
      " test20.jpeg: Spring\n",
      " test21.jpeg: Spring\n",
      " test22.jpeg: Spring\n",
      " test23.jpeg: Autumn\n",
      " test24.jpeg: Summer\n",
      " test25.jpeg: Autumn\n",
      " test26.jpeg: Autumn\n",
      " test27.jpeg: Spring\n",
      " test28.jpeg: Spring\n",
      " test29.jpeg: Autumn\n",
      " test3.jpg: Winter\n",
      " test30.jpeg: Spring\n",
      " test31.jpeg: Winter\n",
      " test32.jpeg: Spring\n",
      " test33.jpeg: Autumn\n",
      " test34.jpeg: Spring\n",
      " test35.jpeg: Spring\n",
      " test36.jpeg: Spring\n",
      " test37.jpeg: Autumn\n",
      " test38.jpeg: Spring\n",
      " test39.jpeg: Spring\n",
      " test4.jpg: Spring\n",
      " test40.jpeg: Spring\n",
      " test41.jpeg: Winter\n",
      " test42.jpeg: Autumn\n",
      " test43.jpeg: Winter\n",
      " test44.jpeg: Winter\n",
      " test45.jpeg: Spring\n",
      " test46.jpeg: Spring\n",
      " test47.jpeg: Winter\n",
      " test48.jpeg: Spring\n",
      " test49.jpeg: Spring\n",
      " test5.jpg: Winter\n",
      " test50.jpeg: Autumn\n",
      " test51.jpeg: Autumn\n",
      " test52.jpeg: Spring\n",
      " test53.jpeg: Spring\n",
      " test54.jpeg: Autumn\n",
      " test55.jpeg: Spring\n",
      " test56.jpeg: Spring\n",
      " test57.jpeg: Spring\n",
      " test58.jpeg: Spring\n",
      " test59.jpeg: Autumn\n",
      " test6.jpg: Spring\n",
      " test60.jpeg: Spring\n",
      " test61.jpeg: Autumn\n",
      " test62.jpeg: Winter\n",
      " test63.jpeg: Spring\n",
      " test64.jpeg: Spring\n",
      " test65.jpeg: Spring\n",
      " test66.jpeg: Spring\n",
      " test67.jpeg: Winter\n",
      " test68.jpeg: Spring\n",
      " test69.jpeg: Spring\n",
      " test7.jpg: Spring\n",
      " test70.jpeg: Winter\n",
      " test71.jpeg: Spring\n",
      " test72.jpeg: Spring\n",
      " test73.jpeg: Autumn\n",
      " test74.jpeg: Winter\n",
      " test75.jpeg: Winter\n",
      " test76.jpeg: Summer\n",
      " test77.jpeg: Spring\n",
      " test78.jpeg: Spring\n",
      " test79.jpeg: Spring\n",
      " test8.jpg: Winter\n",
      " test80.jpeg: Summer\n",
      " test81.jpeg: Spring\n",
      " test82.jpeg: Summer\n",
      " test83.jpeg: Spring\n",
      " test84.jpeg: Spring\n",
      " test85.jpeg: Autumn\n",
      " test86.jpeg: Spring\n",
      " test87.jpeg: Spring\n",
      " test9.jpg: Winter\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T13:28:11.319676Z",
     "start_time": "2025-06-13T13:28:00.719817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏\n",
    "df_true = pd.read_csv(\"true_labels.csv\")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏, —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –≤ —Ü–∏–∫–ª–µ\n",
    "predicted = []\n",
    "\n",
    "for test_img_name in test_images:\n",
    "    test_image_path = os.path.join(test_folder, test_img_name)\n",
    "    test_image = preprocess(Image.open(test_image_path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        test_embedding = model.encode_image(test_image)\n",
    "    test_embedding = test_embedding / test_embedding.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    similarities = [cosine_similarity(test_embedding, ref_emb).item() for ref_emb in reference_embeddings]\n",
    "    best_index = int(np.argmax(similarities))\n",
    "    predicted_type = reference_labels[best_index]\n",
    "\n",
    "    predicted.append((test_img_name, predicted_type))\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\n",
    "df_pred = pd.DataFrame(predicted, columns=[\"filename\", \"predicted_type\"])\n",
    "\n",
    "# –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å true labels\n",
    "df_merged = pd.merge(df_true, df_pred, on=\"filename\")\n",
    "\n",
    "# –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å\n",
    "print(\"\\nüìä Classification Report:\\n\")\n",
    "print(classification_report(df_merged[\"color_type\"], df_merged[\"predicted_type\"]))\n"
   ],
   "id": "da5253daa281ae46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      autumn       0.50      0.43      0.46        21\n",
      "      spring       0.32      0.71      0.44        21\n",
      "      summer       0.25      0.04      0.07        24\n",
      "      winter       0.39      0.33      0.36        21\n",
      "\n",
      "    accuracy                           0.37        87\n",
      "   macro avg       0.36      0.38      0.33        87\n",
      "weighted avg       0.36      0.37      0.32        87\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2aa378b9319cf9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
